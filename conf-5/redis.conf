################################## INCLUDES ###################################

#* 공통으로 적용할 템플릿 설정 파일을 include 할 수 있다.
#* redis는 설정을 중복 기술한 경우 맨 마지막에 기술한 설정을 반영한다.
#* include 파일을 맨 앞에 설정하면 이후 중복된 설정이 있다면 이후 설정이 반영된다.
#* include 파일을 맨 뒤에 설정하면 include 파일을 내용이 앞에 중복된 설정은 무시된다.

#* 'config rewrite'가 적용시 include 파일을 수정하지 않는다.
#   - config rewrite 대상이 redis.conf 에 있다면 그 부분이 수정된다.  (무효 또는 유효)
#   - config rewrite 대상이 redis.conf에 없다면 맨마지막에 추가된다. (항상 유효한 설정)


################################## MODULES ####################################

#* 모듈 코드(C언어)를 작성하여 레디스를 일부 기능을 커스트마이징 할 수 있다.
#* 커스트마이징 할게 없으면 해당 기능은 쓸 일이 없다.
# loadmodule /path/to/my_module.so
# loadmodule /path/to/other_module.so



################################## NETWORK ####################################


#* 로컬 루프백 인터페이스로만 접근 가능
#bind 127.0.0.1
#
#* 특정 인터페이스만 접근 가능하도록 설정
#bind 172.27.27.10 172.27.28.10
#
#* 모든 인터페이스에서 접근 가능
bind 0.0.0.0

#* bind와 auth 설정 모두 안되어 있는 경우, 자동으로 로컬 루프백만 접근 가능하도록 할지 결정
protected-mode yes

#* 클러스터 모드에서 서버간 통신은 port +10000=16379를 사용
port 6379

#* TCP backlog : TCP SYN 연결과 TCP 소켓 연결을 받아 들이는 버퍼 크기로 보면 됨
#* 리눅스의 TCP SYN 연결 버퍼 -> TCP 소켓 연결 버퍼 -> Redis서버의 연결 버퍼(tcp-backlog) 단계로 설정됨 
#* TCP SYN 연결 버퍼 크기 설정
#  sysctl -w net.ipv4.tcp_max_syn_backlog=10000
#  echo "net.ipv4.tcp_max_syn_backlog=10000" >> /etc/sysctl.conf
#* TCP 소켓 연결 버퍼 크기 설정
#  sysctl -w net.core.somaxconn=65535
#  echo "net.core.somaxconn=65535" >> /etc/sysctl.conf
tcp-backlog 511


#* Redis 전용 서버로 구성하기 때문에 UNIXSOCKET은 사용할 필요 없음.
# unixsocket /tmp/redis.sock
# unixsocketperm 700


#* 클라이언트의 TCP 연결 유지 관리 옵셥으로 timeout 과 tcp-keepalive 사용
#* timeout : 클라이언트가 idle 시간(초)이 되면 연결 종료, 0은 기능 off
#* tcp-keepalive : 300초(5분) 간격으로 health-check하고 동작 안하는 클라이언트 연결 종료
#* 해당 값은 권장값이나, timeout에 대해선 동작하도록 고민 필요
timeout 0
tcp-keepalive 300


################################## GENERAL ####################################

#* systemd를 통해 start, stop, restart, auto-start를 관리
#* redis.service의 Type=notify 이므로, 
#* redis.conf 에서는 daemonize no / supervised systemd 로 설정 필요
supervised systemd
daemonize no

#* main 프로세스의 pid값을 정상 실행되면 아래 경로에 반영하며, 정상 종료되면 삭제가 됨. 
pidfile /var/run/redis/redis.pid

#* 로그 파일 생성 패스
logfile /var/log/redis/redis.log

#* 로그레벨 옵션
# debug       :   '.'   많은 로그가 남습니다. 개발/테스트 용도로 사용합니다.
# verbose     :   '-'   디버그 레벨보다는 덜하지만 여전히 많은 로그가 남습니다.
# notice       :   '*'   운영(production)환경에 적합합니다.
# warning     :   '#'   중요하거나 심각한 메시지만 로깅합니다.
loglevel notice

#* Redis에서 database의 의미는 구분된 key space를 말함
#* 동일한 key이지만 database가 다르면 다른 key임
#* database 100만개도 생성이 되는 것으로 보아, 허용 최대 개수는 아직 모르겠음. 
databases 16

#* 로그에 로고 사용 여부
always-show-logo yes

#* syslog는 좀 더 공부가 필요하며, 필요성은 고민해야 함.
#* /var/log/syslog에 로그가 남는다.
syslog-enabled yes

#* 로그 구분을 위한 identity.
syslog-ident REDIS

#* 아직 옵션에 대한 이해가 안됨.
#* Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7.
# syslog-facility local0


################################ SNAPSHOTTING  ################################

#* 멀티로 지정할 수 있으며, <second> <changes>는 AND 조건임
#* SAVE 기능을 사용하지 않으려면 아래 save를 모두 주석(comment)처리하거나 SAVE "" (이전 설정X, 권장옵션)
#* 변경이 빈번하면 이전 작업이 끝나지도 않았는데 반복적인 SAVE 동작으로 문제 발생 가능성 있음.
#* COW 발생으로 과도한 메모 부족 문제 가능성 있음

save 900 1
save 300 10
save 60   10000   
#[권장] save ""

#* bgSAVE 실패시 자동으로 write COMMAND가 동작하지 않도록 하며, 
#* bgSAVE가 복구되면 다시 write COMMAND를 동작시킨다.
#* SAVE 기능에 문제가 있음을 바로 noti. 될 수 있는 장점이 있으나,
#* 서비스 장애를 통해 noti. 되는 것은 바람직하지 않음.
#* redis-cli info persistence 로 정보를 모아 사전 모니터링 및 alert noti. 필요
#[권장] stop-writes-on-bgsave-error no
stop-writes-on-bgsave-error yes

#* RDB파일 압축 : CPU 사용률 증가, DISK 사용량 감소
#* 압축률을 확인해 보자.
#   - redis-server : used_memory_human:149.00M
     - 압축 사용 : 7.5M
	 - 압축 미사용: 116M 
rdbcompression yes

#* rdb 파일명은 테넌트+서버별 유니크한 이름으로 만들어야 한다.
dbfilename dump.rdb

#* persist 동작시 RDB, AOF 파일 등을 저장하는 패스 
dir /var/lib/redis/

############################## APPEND ONLY MODE ###############################

#* AOF 활성화
appendonly yes

#* AOF 파일(redis.dat와 마찬가지로 텐넌트별 서버별 구분해야 한다.)
appendfilename "appendonly.aof"

# [권장] everysec
# always: 매 쓰기 명령이 실행될 때마다 fsync()를 실행합니다. 성능이 매우 떨어지지만 안전합니다.
# everysec: 1초 동안의 데이터를 모아서 별도의 쓰레드가 fsync()를 실행합니다. 성능과 데이터 안전성 면에서 올바른 선택입니다.
# no: 레디스가 fsync()를 실행하지 않습니다. OS가 주기적(30초)으로 fsync()를 실행해서 데이터를 디스크에 저장합니다. 성능은 좋을 수 있지만 데이터 유실의 가능성이 있습니다.
appendfsync everysec

# redis서버가 시작할 AOF파일을 기준으로 100% 증가하면 AOF를 다시 작성한다 - 기존 히스토리 내역은 삭제되고 현재 기준으로.
# AOF 파일이 작은 경우, 빈번한 rewrite를 방지를 위해서 auto-aof-rewrite-min-size 이하이면 rewrite 동작하지 않게 할 수 있다.
# 참고로, AOF는 변경된 내용 이력을 command 단위로 기록한다.
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb

#* [권장] yes 이나, replica는 no(저장관점), master는 yes(성능관점) 로 운영하는 것이 좋을 듯...
# 레디스 서버가 대량의 데이터를 디스크에 쓰는 경우는 RDB 파일을 쓸때와 AOF 파일을 쓸(Rewrite)때 이다.
# 메모리에 있는 데이터의 크기와 디스크 성능에 따라 몇 초에서 몇 분이 걸릴 수도 있다.
# 이 동안 fsync()가 수행되어 성능에 문제가 될 수도 있다.
# Appendfsync를 always 나 everysec로 설정했을때, 대량 쓰기 동안 fsync() 수행 여부를 정하는 파라미터가 no-appendfsync-on-rewrite 이다.
# No로 설정하면 대량 쓰기 동안 설정된 대로 fsync()를 수행한다.
# Yes로 설정하면 대량 쓰기 동안 레디스 서버에서 fsync()를 수행하지 않고 운영체제에게 맡긴다.
# 그러면 30초 마다 한 번씩 fsync()가 수행된다. 즉, Appendfsync를 no로 설정한 것과 같다.
# 기본값은 no이다. No로 설정한 상태에서 운영했을 때 별 문제가 없다면 그대로 운영한다.
# 만약 응답시간에 늦어서 문제가 될 경우 Yes로 설정한다. 이 설정은 데이터가 제때 AOF에 기록되지 못할 수도 있음을 알고 있어야 한다#
no-appendfsync-on-rewrite yes

# 레디스 시작 시 AOF 파일을 메모리로 로드할 때 AOF 파일 끝이 잘린(truncated)것을 발견할 수 있습니다.
# 레디스가 실행중에 크레시(crash), 특히 ext4 파일시스템을 data=ordered 옵션없이 마운트된 경우
# (레디스가 크레시 되었지만 운영체제가 여전히 올바르게 동작하는 경우 발생하지 않습니다) 발생할 수 있습니다.
# Yes: 레디스는 가능한 많은 데이터를 로드하고 관리자에게 알리기 위해 관련 내용을 로그에 남깁니다. 레디스는 정상적으로 시작합니다.
# No: 레디스는 오류를 남기고 중단합니다. 이 경우 "redis-check-aof"유틸리티를 사용하여 AOF 파일을 수정해야합니다.
# AOF 파일이 중간에 손상된 경우 레디스는 오류를 남기고 중단합니다.
aof-load-truncated yes

# AOF rewrite 하면 AOF 파일을 RDB format으로 씁니다.
# 이유는 쓰는 시간을 줄이고 로드하는 시간도 줄이며, AOF 파일 사이즈도 줄일 수 있습니다.
# 단점이라고 하면 RDB format은 binary기 때문에 편집할 수 없습니다.
# 이후 쓰여지는 명령은 기존과 같이 text로 쓰여집니다.
# 4.0에서는 기본값이 no였고, 5.0부터 기본값이 yes로 바뀌었습니다.
aof-use-rdb-preamble yes


################################# REPLICATION #################################

#* MASTER는 해당 옵션 X
#* REPLICA에서 사용
#* REPLICAT 역할 해제시 : `replicaof no one` -> `config rewrite` -> VIP? or DNS? 로 Master로 승격 및 Fail Over
# replicaof <masterip> <masterport>

#* 이 서버가 복제이고 마스터 서버에 password를 설정(requirepass)했을 경우
#* 마스터 서버의 password를 설정, 인증 실패시 복제 거부
#* Replica에서 이 옵션을 사용 안하면 마스터의 requirepass 설정 여부와 무관하게 복제 가능성
#* 이 옵션의 용도는 무엇인가? 의미가 없는 것 같은데...
# masterauth <master-password>

#* replica가 쓰기 모드가 가능하면 정합성이 깨지게 된다.
#* replica가 읽기 전용 모드가 되어야 master(쓰기) - replica(읽기) 형태 구성이 가능하다.
#* 따라서, 해당 옵션은 강제적으로 yes만 설정해야 한다.
replica-read-only yes

#* master와 replica간 연결이 끊어졌을 때, 재연결되면 부분 복제를 수행하기 위한 master의 버퍼
#* master/replica 모두 동일값으로 설정해야 한다. (http://redisgate.kr/redis/server/psync2.php)
#* 64mb가 권장으로 되어 있는데, 실제 물리적 메모리 크기와 replica 수에 따라 달라지지 않을까?
repl-backlog-size 64MB

#* 부분 복제를 위한 버퍼의 유지 TTL
#* master는 replica와 연결이 끊어지면 repl-backlog-ttl후 버퍼 해제
#* replica는 mastr와 연결이 끊어져도 버퍼 유지 (master 승격 대비)
repl-backlog-ttl 3600

#* replica -> master로 PING 요청의 설정이다. (10초가 default값)
#* 참고로 master -> replica로 1초에 한번씩 replconf 요청을 한다.
repl-ping-replica-period 10

#* 다음 3가지의 경우에 master/replica간 time-out 난 것으로 판단한다.
#  복제 서버 관점: 마스터로 부터 데이터가 timeout 시간(repl-timeout) 동안 오지 않거나 ping에 응답(repl-ping-replica-period)이 없을 때
#  복제 서버 관점: 동기화(sync) 중 마지막 전송 받은 시간이 timemout 시간(repl-timeout)을 초과할 때
#  마스터 서버 관점: 복제 서버로 replconf에 대한 응답(ack)가 timemout 시간 동안 없을 때
repl-timeout 60

#* replica관점에서 master와 연결이 끊어졌을 때 동작 방식 설정X
#* yes : 클라이언트 요청에 응답
#* no : 일부 명령어만 받고 나머지는 거부
replica-serve-stale-data yes

#* sentinel 구성에서 master 장애시 복수의 replica간 master로 승격시켜는 우선 순위 결정
#* 0은 승격제외이며, 낮은 값이 우선순위를 갖는다.
replica-priority 100

#* 복제시 rdb 파일을 생성하는데 rdb파일을 disk에 만들지 않고 바로 소켓에 쓰기하여 전송
#* [권장] yes
repl-diskless-sync yes

#* diskless-sync 방식 사용시, replica의 복제 요청시 delay 시간 지정
#* 다수의 replica가 동시 접속시 네트워크부하 및 redis-server부하를 감안한 조치
#* [권장] 0 : replica가 다수가 아니고 네트워크 대역폭이 충분하다는 가정
repl-diskless-sync-delay 0

#* master/replica간 full복제시 데이터 전송단위를 크게 할 것인지
*  yes : 마스터와 복제 서버간 여러 네트워크 장비가 있는 경우 또는 대역폭(bandwidth)이 작고 원거리인 경우 유리
repl-disable-tcp-nodelay no

#* master가 replica로 보내는 replconf에 대한 ACK가 10초내에 오지 않으면 
#* min_slaves_good_slaves 값을 1씩 감소시킨다.
#* default값으로 아래는 셋팅
min-replicas-max-lag 10     

#* min_slaves_good_slaves 값이 min-replicas-to-writer값이 되면 master는 더 이상의 write를 허용하지 않음
#* default값으로 아래는 셋팅(0은 비활성화)
min-replicas-to-write 0

#* 이해가 안되는 옵션
# replica-announce-ip 5.5.5.5
# replica-announce-port 1234


################################## SECURITY ###################################

#* 초당 15만번 재시도를 할 수 있음으로 사용시 강력한 패스워드 작성 필요
# requirepass <password>

#* 경쟁사 분석을 통해 공통 요소 두출필요
# CONFIG를 알수 없는 name으로 변경
# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52
# CONFIG를 아예 사용 못하도록 변경
# rename-command CONFIG ""


################################### CLIENTS ####################################

#* 기본값은 1만이다.
#* 서버 사양에 따른 디펜던시가 있는 값으로 보임.
#* 그러나, 10000~65535 사이에 값을 고객이 결정하게 하거나,
#* 서버 사양별(Flavor)별 권장값을 정해야함, 물론 커널, 오픈파일 수 등 설정도 별도로 해야함.
# maxclients 10000


############################## MEMORY MANAGEMENT ################################

#* persist, replica 동작시 COW(copy on write)로 인해 추가적인 메모리 용량 필요
#* 안정적 persist, replica 동작을 위해서는
#* 물리적 RAM 크기의 50%, 60%, 70% 중 선택할 수 있어야 한다.
#* 50~60% : 강대명 권고
#* 70% :  RedisGate

maxmemory 615MB

# MAXMEMORY 정책: 설정한 메모리 한계치까지 사용했을 때 어떻게 할지를 정합니다.
# volatile-lru -> 만료 시간이 설정된 키중에서 근사 LRU로 삭제할 키를 정한다.
# allkeys-lru -> 모든 키중에서 근사 LRU로 삭제할 키를 정한다.
# volatile-lfu -> 만료 시간이 설정된 키중에서 근사 LFU로 삭제할 키를 정한다.
# allkeys-lfu -> 모든 키중에서 근사 LFU로 삭제할 키를 정한다.
# volatile-random -> 만료 시간이 설정된 키중에서 임의(random)로 삭제할 키를 정한다.
# allkeys-random -> 모든 키중에서 임의로 삭제할 키를 정한다.
# volatile-ttl -> 만료시간이 가장 가까운 키 순으로 삭제한다.
# noeviction -> 키를 삭제하지 않는다. 쓰기 명령에 에러를 리턴한다.
#   LRU: Least Recently Used
#  LFU: Least Frequently Used
# LRU, LFU, TTL은 근사 임의 알고리즘으로 구현되어 있습니다.
# 퇴출할(eviction) 적당한 키가 없으면 레디스 서버는 에러를 리턴합니다.
# 기본값은 noeviction 이다.
maxmemory-policy noeviction

# 삭제할 키를 선정하는 샘플수 - 5가 적당하다고 권장됨.
maxmemory-samples 5


#* 디폴트값이 yes : 권장 값임.
#* yes인 경우 replica가 master로 승격하면 그 때부터 maxmemory가 적용됨
replica-ignore-maxmemory yes

############################# LAZY FREEING ####################################

#* 삭제가 발생할 경우 unlink 명령어로 대체하여 비동기적으로 동작할 지 결정
#* 성능성 유리함으로 사용이 바람직.
#* 다만 위급상황(메모리 부족)에서는 신속한 조치(LAZY 동작임)가 안되는 것이 단점

# Yes로 설정하면 maxmemory 정책으로 키를 삭제할 때 UNLINK를 사용
lazyfree-lazy-eviction yes
# Yes로 설정하면 만료된(expired) 키를 삭제할 때 UNLINK를 사용
lazyfree-lazy-expire yes
# RENAME 명령을 사용시도 기존 키와 값이 삭제후 변경되는데 UNLINK를 사용
lazyfree-lazy-server-del yes
# 전체 동기화(Full Sync)할 때 복제 서버는 자신이 기존에 가지고 있는 모든 데이터를 지움.
# Yes로 설정하면 Flushall async로 지웁
replica-lazy-flush yes

################################ LUA SCRIPTING  ###############################

#* 루아 스트립트(Lua script) 최대 실행 시간(ms)
#* 매니지먼트 서비스에서 루아 스크립트를 지원이 타당한지 의문?
#* 타사 사례가 필요함.
lua-time-limit 5000

################################## SLOW LOG ###################################
# 슬로우 로그(Slow log)는 설정한 실행 시간을 초과하는 쿼리들을 기록에 남기는 시스템
#* 성능 분석에 중요한 도구.
#* slowlog 커맨드로 볼 수 있다.

#* microseconds 단위이며 기본값은 10ms 임.
slowlog-log-slower-than 10000
#* 최대 128개의 SLOW 로그를 메모리에 저장하는 것이며, 꽉차면 오래된 것을 삭제한다.
slowlog-max-len 128

################################ LATENCY MONITOR ##############################

#* millisecond 단위로 수행되는 오퍼레이션을 기록
#* 디폴트값은 0이며 0은 비활성화.
#* 응답시간의 이슈가 발생하면 CONFIG SET latency-monitor-threshold <milliseconds>
#  로 원인 분석에 사용
#* http://redisgate.kr/redis/server/latency.php
latency-monitor-threshold 0


################################ REDIS CLUSTER  ###############################

# Normal Redis instances can't be part of a Redis Cluster; only nodes that are
# started as cluster nodes can. In order to start a Redis instance as a
# cluster node enable the cluster support uncommenting the following:
#
# cluster-enabled yes

# Every cluster node has a cluster configuration file. This file is not
# intended to be edited by hand. It is created and updated by Redis nodes.
# Every Redis Cluster node requires a different cluster configuration file.
# Make sure that instances running in the same system do not have
# overlapping cluster configuration file names.
#
# cluster-config-file nodes-6379.conf

# Cluster node timeout is the amount of milliseconds a node must be unreachable
# for it to be considered in failure state.
# Most other internal time limits are multiple of the node timeout.
#
# cluster-node-timeout 15000

# A replica of a failing master will avoid to start a failover if its data
# looks too old.
#
# There is no simple way for a replica to actually have an exact measure of
# its "data age", so the following two checks are performed:
#
# 1) If there are multiple replicas able to failover, they exchange messages
#    in order to try to give an advantage to the replica with the best
#    replication offset (more data from the master processed).
#    Replicas will try to get their rank by offset, and apply to the start
#    of the failover a delay proportional to their rank.
#
# 2) Every single replica computes the time of the last interaction with
#    its master. This can be the last ping or command received (if the master
#    is still in the "connected" state), or the time that elapsed since the
#    disconnection with the master (if the replication link is currently down).
#    If the last interaction is too old, the replica will not try to failover
#    at all.
#
# The point "2" can be tuned by user. Specifically a replica will not perform
# the failover if, since the last interaction with the master, the time
# elapsed is greater than:
#
#   (node-timeout * replica-validity-factor) + repl-ping-replica-period
#
# So for example if node-timeout is 30 seconds, and the replica-validity-factor
# is 10, and assuming a default repl-ping-replica-period of 10 seconds, the
# replica will not try to failover if it was not able to talk with the master
# for longer than 310 seconds.
#
# A large replica-validity-factor may allow replicas with too old data to failover
# a master, while a too small value may prevent the cluster from being able to
# elect a replica at all.
#
# For maximum availability, it is possible to set the replica-validity-factor
# to a value of 0, which means, that replicas will always try to failover the
# master regardless of the last time they interacted with the master.
# (However they'll always try to apply a delay proportional to their
# offset rank).
#
# Zero is the only value able to guarantee that when all the partitions heal
# the cluster will always be able to continue.
#
# cluster-replica-validity-factor 10

# Cluster replicas are able to migrate to orphaned masters, that are masters
# that are left without working replicas. This improves the cluster ability
# to resist to failures as otherwise an orphaned master can't be failed over
# in case of failure if it has no working replicas.
#
# Replicas migrate to orphaned masters only if there are still at least a
# given number of other working replicas for their old master. This number
# is the "migration barrier". A migration barrier of 1 means that a replica
# will migrate only if there is at least 1 other working replica for its master
# and so forth. It usually reflects the number of replicas you want for every
# master in your cluster.
#
# Default is 1 (replicas migrate only if their masters remain with at least
# one replica). To disable migration just set it to a very large value.
# A value of 0 can be set but is useful only for debugging and dangerous
# in production.
#
# cluster-migration-barrier 1

# By default Redis Cluster nodes stop accepting queries if they detect there
# is at least an hash slot uncovered (no available node is serving it).
# This way if the cluster is partially down (for example a range of hash slots
# are no longer covered) all the cluster becomes, eventually, unavailable.
# It automatically returns available as soon as all the slots are covered again.
#
# However sometimes you want the subset of the cluster which is working,
# to continue to accept queries for the part of the key space that is still
# covered. In order to do so, just set the cluster-require-full-coverage
# option to no.
#
# cluster-require-full-coverage yes

# This option, when set to yes, prevents replicas from trying to failover its
# master during master failures. However the master can still perform a
# manual failover, if forced to do so.
#
# This is useful in different scenarios, especially in the case of multiple
# data center operations, where we want one side to never be promoted if not
# in the case of a total DC failure.
#
# cluster-replica-no-failover no

# In order to setup your cluster make sure to read the documentation
# available at http://redis.io web site.

########################## CLUSTER DOCKER/NAT support  ########################

# In certain deployments, Redis Cluster nodes address discovery fails, because
# addresses are NAT-ted or because ports are forwarded (the typical case is
# Docker and other containers).
#
# In order to make Redis Cluster working in such environments, a static
# configuration where each node knows its public address is needed. The
# following two options are used for this scope, and are:
#
# * cluster-announce-ip
# * cluster-announce-port
# * cluster-announce-bus-port
#
# Each instruct the node about its address, client port, and cluster message
# bus port. The information is then published in the header of the bus packets
# so that other nodes will be able to correctly map the address of the node
# publishing the information.
#
# If the above options are not used, the normal Redis Cluster auto-detection
# will be used instead.
#
# Note that when remapped, the bus port may not be at the fixed offset of
# clients port + 10000, so you can specify any port and bus-port depending
# on how they get remapped. If the bus-port is not set, a fixed offset of
# 10000 will be used as usually.
#
# Example:
#
# cluster-announce-ip 10.1.1.5
# cluster-announce-port 6379
# cluster-announce-bus-port 6380


############################# EVENT NOTIFICATION ##############################

# Redis can notify Pub/Sub clients about events happening in the key space.
# This feature is documented at http://redis.io/topics/notifications
#
# For instance if keyspace events notification is enabled, and a client
# performs a DEL operation on key "foo" stored in the Database 0, two
# messages will be published via Pub/Sub:
#
# PUBLISH __keyspace@0__:foo del
# PUBLISH __keyevent@0__:del foo
#
# It is possible to select the events that Redis will notify among a set
# of classes. Every class is identified by a single character:
#
#  K     Keyspace events, published with __keyspace@<db>__ prefix.
#  E     Keyevent events, published with __keyevent@<db>__ prefix.
#  g     Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...
#  $     String commands
#  l     List commands
#  s     Set commands
#  h     Hash commands
#  z     Sorted set commands
#  x     Expired events (events generated every time a key expires)
#  e     Evicted events (events generated when a key is evicted for maxmemory)
#  A     Alias for g$lshzxe, so that the "AKE" string means all the events.
#
#  The "notify-keyspace-events" takes as argument a string that is composed
#  of zero or multiple characters. The empty string means that notifications
#  are disabled.
#
#  Example: to enable list and generic events, from the point of view of the
#           event name, use:
#
#  notify-keyspace-events Elg
#
#  Example 2: to get the stream of the expired keys subscribing to channel
#             name __keyevent@0__:expired use:
#
#  notify-keyspace-events Ex
#
#  By default all notifications are disabled because most users don't need
#  this feature and the feature has some overhead. Note that if you don't
#  specify at least one of K or E, no events will be delivered.
notify-keyspace-events ""

############################### ADVANCED CONFIG ###############################

# Hashes are encoded using a memory efficient data structure when they have a
# small number of entries, and the biggest entry does not exceed a given
# threshold. These thresholds can be configured using the following directives.
hash-max-ziplist-entries 512
hash-max-ziplist-value 64

# Lists are also encoded in a special way to save a lot of space.
# The number of entries allowed per internal list node can be specified
# as a fixed maximum size or a maximum number of elements.
# For a fixed maximum size, use -5 through -1, meaning:
# -5: max size: 64 Kb  <-- not recommended for normal workloads
# -4: max size: 32 Kb  <-- not recommended
# -3: max size: 16 Kb  <-- probably not recommended
# -2: max size: 8 Kb   <-- good
# -1: max size: 4 Kb   <-- good
# Positive numbers mean store up to _exactly_ that number of elements
# per list node.
# The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size),
# but if your use case is unique, adjust the settings as necessary.
list-max-ziplist-size -2

# Lists may also be compressed.
# Compress depth is the number of quicklist ziplist nodes from *each* side of
# the list to *exclude* from compression.  The head and tail of the list
# are always uncompressed for fast push/pop operations.  Settings are:
# 0: disable all list compression
# 1: depth 1 means "don't start compressing until after 1 node into the list,
#    going from either the head or tail"
#    So: [head]->node->node->...->node->[tail]
#    [head], [tail] will always be uncompressed; inner nodes will compress.
# 2: [head]->[next]->node->node->...->node->[prev]->[tail]
#    2 here means: don't compress head or head->next or tail->prev or tail,
#    but compress all nodes between them.
# 3: [head]->[next]->[next]->node->node->...->node->[prev]->[prev]->[tail]
# etc.
list-compress-depth 0

# Sets have a special encoding in just one case: when a set is composed
# of just strings that happen to be integers in radix 10 in the range
# of 64 bit signed integers.
# The following configuration setting sets the limit in the size of the
# set in order to use this special memory saving encoding.
set-max-intset-entries 512

# Similarly to hashes and lists, sorted sets are also specially encoded in
# order to save a lot of space. This encoding is only used when the length and
# elements of a sorted set are below the following limits:
zset-max-ziplist-entries 128
zset-max-ziplist-value 64

# HyperLogLog sparse representation bytes limit. The limit includes the
# 16 bytes header. When an HyperLogLog using the sparse representation crosses
# this limit, it is converted into the dense representation.
#
# A value greater than 16000 is totally useless, since at that point the
# dense representation is more memory efficient.
#
# The suggested value is ~ 3000 in order to have the benefits of
# the space efficient encoding without slowing down too much PFADD,
# which is O(N) with the sparse encoding. The value can be raised to
# ~ 10000 when CPU is not a concern, but space is, and the data set is
# composed of many HyperLogLogs with cardinality in the 0 - 15000 range.
hll-sparse-max-bytes 3000

# Streams macro node max size / items. The stream data structure is a radix
# tree of big nodes that encode multiple items inside. Using this configuration
# it is possible to configure how big a single node can be in bytes, and the
# maximum number of items it may contain before switching to a new node when
# appending new stream entries. If any of the following settings are set to
# zero, the limit is ignored, so for instance it is possible to set just a
# max entires limit by setting max-bytes to 0 and max-entries to the desired
# value.
stream-node-max-bytes 4096
stream-node-max-entries 100

# Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in
# order to help rehashing the main Redis hash table (the one mapping top-level
# keys to values). The hash table implementation Redis uses (see dict.c)
# performs a lazy rehashing: the more operation you run into a hash table
# that is rehashing, the more rehashing "steps" are performed, so if the
# server is idle the rehashing is never complete and some more memory is used
# by the hash table.
#
# The default is to use this millisecond 10 times every second in order to
# actively rehash the main dictionaries, freeing memory when possible.
#
# If unsure:
# use "activerehashing no" if you have hard latency requirements and it is
# not a good thing in your environment that Redis can reply from time to time
# to queries with 2 milliseconds delay.
#
# use "activerehashing yes" if you don't have such hard requirements but
# want to free memory asap when possible.
activerehashing yes

# The client output buffer limits can be used to force disconnection of clients
# that are not reading data from the server fast enough for some reason (a
# common reason is that a Pub/Sub client can't consume messages as fast as the
# publisher can produce them).
#
# The limit can be set differently for the three different classes of clients:
#
# normal -> normal clients including MONITOR clients
# replica  -> replica clients
# pubsub -> clients subscribed to at least one pubsub channel or pattern
#
# The syntax of every client-output-buffer-limit directive is the following:
#
# client-output-buffer-limit <class> <hard limit> <soft limit> <soft seconds>
#
# A client is immediately disconnected once the hard limit is reached, or if
# the soft limit is reached and remains reached for the specified number of
# seconds (continuously).
# So for instance if the hard limit is 32 megabytes and the soft limit is
# 16 megabytes / 10 seconds, the client will get disconnected immediately
# if the size of the output buffers reach 32 megabytes, but will also get
# disconnected if the client reaches 16 megabytes and continuously overcomes
# the limit for 10 seconds.
#
# By default normal clients are not limited because they don't receive data
# without asking (in a push way), but just after a request, so only
# asynchronous clients may create a scenario where data is requested faster
# than it can read.
#
# Instead there is a default limit for pubsub and replica clients, since
# subscribers and replicas receive data in a push fashion.
#
# Both the hard or the soft limit can be disabled by setting them to zero.
client-output-buffer-limit normal 0 0 0
client-output-buffer-limit replica 256mb 64mb 60
client-output-buffer-limit pubsub 32mb 8mb 60

# Client query buffers accumulate new commands. They are limited to a fixed
# amount by default in order to avoid that a protocol desynchronization (for
# instance due to a bug in the client) will lead to unbound memory usage in
# the query buffer. However you can configure it here if you have very special
# needs, such us huge multi/exec requests or alike.
#
# client-query-buffer-limit 1gb

# In the Redis protocol, bulk requests, that are, elements representing single
# strings, are normally limited ot 512 mb. However you can change this limit
# here.
#
# proto-max-bulk-len 512mb

# Redis calls an internal function to perform many background tasks, like
# closing connections of clients in timeout, purging expired keys that are
# never requested, and so forth.
#
# Not all tasks are performed with the same frequency, but Redis checks for
# tasks to perform according to the specified "hz" value.
#
# By default "hz" is set to 10. Raising the value will use more CPU when
# Redis is idle, but at the same time will make Redis more responsive when
# there are many keys expiring at the same time, and timeouts may be
# handled with more precision.
#
# The range is between 1 and 500, however a value over 100 is usually not
# a good idea. Most users should use the default of 10 and raise this up to
# 100 only in environments where very low latency is required.
hz 10

# Normally it is useful to have an HZ value which is proportional to the
# number of clients connected. This is useful in order, for instance, to
# avoid too many clients are processed for each background task invocation
# in order to avoid latency spikes.
#
# Since the default HZ value by default is conservatively set to 10, Redis
# offers, and enables by default, the ability to use an adaptive HZ value
# which will temporary raise when there are many connected clients.
#
# When dynamic HZ is enabled, the actual configured HZ will be used as
# as a baseline, but multiples of the configured HZ value will be actually
# used as needed once more clients are connected. In this way an idle
# instance will use very little CPU time while a busy instance will be
# more responsive.
dynamic-hz yes

# When a child rewrites the AOF file, if the following option is enabled
# the file will be fsync-ed every 32 MB of data generated. This is useful
# in order to commit the file to the disk more incrementally and avoid
# big latency spikes.
aof-rewrite-incremental-fsync yes

# When redis saves RDB file, if the following option is enabled
# the file will be fsync-ed every 32 MB of data generated. This is useful
# in order to commit the file to the disk more incrementally and avoid
# big latency spikes.
rdb-save-incremental-fsync yes

# Redis LFU eviction (see maxmemory setting) can be tuned. However it is a good
# idea to start with the default settings and only change them after investigating
# how to improve the performances and how the keys LFU change over time, which
# is possible to inspect via the OBJECT FREQ command.
#
# There are two tunable parameters in the Redis LFU implementation: the
# counter logarithm factor and the counter decay time. It is important to
# understand what the two parameters mean before changing them.
#
# The LFU counter is just 8 bits per key, it's maximum value is 255, so Redis
# uses a probabilistic increment with logarithmic behavior. Given the value
# of the old counter, when a key is accessed, the counter is incremented in
# this way:
#
# 1. A random number R between 0 and 1 is extracted.
# 2. A probability P is calculated as 1/(old_value*lfu_log_factor+1).
# 3. The counter is incremented only if R < P.
#
# The default lfu-log-factor is 10. This is a table of how the frequency
# counter changes with a different number of accesses with different
# logarithmic factors:
#
# +--------+------------+------------+------------+------------+------------+
# | factor | 100 hits   | 1000 hits  | 100K hits  | 1M hits    | 10M hits   |
# +--------+------------+------------+------------+------------+------------+
# | 0      | 104        | 255        | 255        | 255        | 255        |
# +--------+------------+------------+------------+------------+------------+
# | 1      | 18         | 49         | 255        | 255        | 255        |
# +--------+------------+------------+------------+------------+------------+
# | 10     | 10         | 18         | 142        | 255        | 255        |
# +--------+------------+------------+------------+------------+------------+
# | 100    | 8          | 11         | 49         | 143        | 255        |
# +--------+------------+------------+------------+------------+------------+
#
# NOTE: The above table was obtained by running the following commands:
#
#   redis-benchmark -n 1000000 incr foo
#   redis-cli object freq foo
#
# NOTE 2: The counter initial value is 5 in order to give new objects a chance
# to accumulate hits.
#
# The counter decay time is the time, in minutes, that must elapse in order
# for the key counter to be divided by two (or decremented if it has a value
# less <= 10).
#
# The default value for the lfu-decay-time is 1. A Special value of 0 means to
# decay the counter every time it happens to be scanned.
#
# lfu-log-factor 10
# lfu-decay-time 1

########################### ACTIVE DEFRAGMENTATION #######################
#
# WARNING THIS FEATURE IS EXPERIMENTAL. However it was stress tested
# even in production and manually tested by multiple engineers for some
# time.
#
# What is active defragmentation?
# -------------------------------
#
# Active (online) defragmentation allows a Redis server to compact the
# spaces left between small allocations and deallocations of data in memory,
# thus allowing to reclaim back memory.
#
# Fragmentation is a natural process that happens with every allocator (but
# less so with Jemalloc, fortunately) and certain workloads. Normally a server
# restart is needed in order to lower the fragmentation, or at least to flush
# away all the data and create it again. However thanks to this feature
# implemented by Oran Agra for Redis 4.0 this process can happen at runtime
# in an "hot" way, while the server is running.
#
# Basically when the fragmentation is over a certain level (see the
# configuration options below) Redis will start to create new copies of the
# values in contiguous memory regions by exploiting certain specific Jemalloc
# features (in order to understand if an allocation is causing fragmentation
# and to allocate it in a better place), and at the same time, will release the
# old copies of the data. This process, repeated incrementally for all the keys
# will cause the fragmentation to drop back to normal values.
#
# Important things to understand:
#
# 1. This feature is disabled by default, and only works if you compiled Redis
#    to use the copy of Jemalloc we ship with the source code of Redis.
#    This is the default with Linux builds.
#
# 2. You never need to enable this feature if you don't have fragmentation
#    issues.
#
# 3. Once you experience fragmentation, you can enable this feature when
#    needed with the command "CONFIG SET activedefrag yes".
#
# The configuration parameters are able to fine tune the behavior of the
# defragmentation process. If you are not sure about what they mean it is
# a good idea to leave the defaults untouched.

# Enabled active defragmentation
# activedefrag yes

# Minimum amount of fragmentation waste to start active defrag
# active-defrag-ignore-bytes 100mb

# Minimum percentage of fragmentation to start active defrag
# active-defrag-threshold-lower 10

# Maximum percentage of fragmentation at which we use maximum effort
# active-defrag-threshold-upper 100

# Minimal effort for defrag in CPU percentage
# active-defrag-cycle-min 5

# Maximal effort for defrag in CPU percentage
# active-defrag-cycle-max 75

# Maximum number of set/hash/zset/list fields that will be processed from
# the main dictionary scan
# active-defrag-max-scan-fields 1000
